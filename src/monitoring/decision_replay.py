"""
Decision Replay Manager

Provides complete replay capability of agent decisions:
- Which node executed
- What prompt was used
- What output was generated
- Full decision context and reasoning
"""

import json
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, asdict, field
from pathlib import Path
import hashlib


@dataclass
class NodeExecution:
    """Record of a single node execution"""
    node_name: str
    start_time: str
    end_time: Optional[str] = None
    duration_ms: float = 0.0
    status: str = "pending"  # pending, success, error
    error: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class PromptContext:
    """Complete prompt context used in decision"""
    template: str
    variables: Dict[str, Any] = field(default_factory=dict)
    system_message: str = ""
    user_message: str = ""
    final_prompt: str = ""
    model: str = "unknown"
    temperature: float = 0.7
    max_tokens: int = 4096
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class OutputGenerated:
    """Output generated by the decision"""
    raw_output: str = ""
    parsed_output: Dict[str, Any] = field(default_factory=dict)
    tool_calls: List[Dict[str, Any]] = field(default_factory=list)
    resources_found: List[str] = field(default_factory=list)
    confidence: str = "unknown"
    token_count: int = 0
    finish_reason: str = "unknown"
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class DecisionReasoning:
    """Reasoning behind the decision"""
    decision_type: str  # route, generate, search, etc.
    rationale: str = ""
    alternatives_considered: List[str] = field(default_factory=list)
    selected_action: str = ""
    confidence_score: float = 0.0
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


@dataclass
class DecisionRecord:
    """Complete record of a single decision"""
    decision_id: str
    timestamp: str
    thread_id: str
    node_execution: NodeExecution
    prompt_context: PromptContext
    output_generated: OutputGenerated
    reasoning: DecisionReasoning
    state_before: Dict[str, Any] = field(default_factory=dict)
    state_after: Dict[str, Any] = field(default_factory=dict)
    tags: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "decision_id": self.decision_id,
            "timestamp": self.timestamp,
            "thread_id": self.thread_id,
            "node_execution": self.node_execution.to_dict(),
            "prompt_context": self.prompt_context.to_dict(),
            "output_generated": self.output_generated.to_dict(),
            "reasoning": self.reasoning.to_dict(),
            "state_before": self.state_before,
            "state_after": self.state_after,
            "tags": self.tags
        }
    
    def to_json(self, indent: int = 2) -> str:
        return json.dumps(self.to_dict(), indent=indent, ensure_ascii=False)


class DecisionReplayManager:
    """
    Manages decision replay functionality.
    
    Provides:
    - Record every decision made by the agent
    - Full replay capability with context
    - Decision tree visualization
    - Performance analysis of decisions
    """
    
    def __init__(self, storage_path: Optional[Path] = None):
        self.storage_path = storage_path or Path("data/monitoring/decisions")
        self.storage_path.mkdir(parents=True, exist_ok=True)
        self.decisions: List[DecisionRecord] = []
        self.active_executions: Dict[str, datetime] = {}
    
    def start_decision(
        self,
        node_name: str,
        thread_id: str,
        state: Dict[str, Any],
        tags: Optional[List[str]] = None
    ) -> str:
        """
        Start recording a decision.
        
        Args:
            node_name: Name of the node being executed
            thread_id: Current thread ID
            state: Current state before decision
            tags: Optional tags
            
        Returns:
            decision_id for tracking
        """
        timestamp = datetime.now(timezone.utc).isoformat()
        
        # Generate decision ID
        decision_data = f"{timestamp}_{node_name}_{thread_id}"
        decision_id = hashlib.sha256(decision_data.encode()).hexdigest()[:16]
        
        # Create node execution
        node_execution = NodeExecution(
            node_name=node_name,
            start_time=timestamp,
            status="pending"
        )
        
        # Create placeholder decision record
        decision = DecisionRecord(
            decision_id=decision_id,
            timestamp=timestamp,
            thread_id=thread_id,
            node_execution=node_execution,
            prompt_context=PromptContext(template="", final_prompt=""),
            output_generated=OutputGenerated(),
            reasoning=DecisionReasoning(decision_type="unknown"),
            state_before=self._sanitize_state(state),
            tags=tags or []
        )
        
        self.decisions.append(decision)
        self.active_executions[decision_id] = datetime.now(timezone.utc)
        
        return decision_id
    
    def record_prompt(
        self,
        decision_id: str,
        prompt_template: str,
        variables: Dict[str, Any],
        final_prompt: str,
        model: str = "unknown",
        temperature: float = 0.7,
        max_tokens: int = 4096
    ):
        """Record the prompt used for this decision"""
        decision = self._get_decision(decision_id)
        if not decision:
            return
        
        # Extract system and user messages from final prompt
        system_msg = ""
        user_msg = final_prompt
        
        if "System:" in final_prompt:
            parts = final_prompt.split("System:", 1)
            if len(parts) == 2:
                rest = parts[1]
                if "User:" in rest:
                    system_msg = rest.split("User:", 1)[0].strip()
                    user_msg = rest.split("User:", 1)[1].strip()
        
        decision.prompt_context = PromptContext(
            template=prompt_template,
            variables=variables,
            system_message=system_msg,
            user_message=user_msg,
            final_prompt=final_prompt,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )
    
    def record_output(
        self,
        decision_id: str,
        raw_output: str,
        parsed_output: Optional[Dict[str, Any]] = None,
        tool_calls: Optional[List[Dict[str, Any]]] = None,
        resources_found: Optional[List[str]] = None,
        confidence: str = "unknown",
        token_count: int = 0,
        finish_reason: str = "stop"
    ):
        """Record the output generated by this decision"""
        decision = self._get_decision(decision_id)
        if not decision:
            return
        
        decision.output_generated = OutputGenerated(
            raw_output=raw_output[:5000],  # Truncate long outputs
            parsed_output=parsed_output or {},
            tool_calls=tool_calls or [],
            resources_found=resources_found or [],
            confidence=confidence,
            token_count=token_count,
            finish_reason=finish_reason
        )
    
    def record_reasoning(
        self,
        decision_id: str,
        decision_type: str,
        rationale: str,
        selected_action: str,
        alternatives: Optional[List[str]] = None,
        confidence: float = 0.0,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """Record the reasoning behind this decision"""
        decision = self._get_decision(decision_id)
        if not decision:
            return
        
        decision.reasoning = DecisionReasoning(
            decision_type=decision_type,
            rationale=rationale,
            alternatives_considered=alternatives or [],
            selected_action=selected_action,
            confidence_score=confidence,
            metadata=metadata or {}
        )
    
    def end_decision(
        self,
        decision_id: str,
        state: Dict[str, Any],
        status: str = "success",
        error: Optional[str] = None
    ):
        """
        Complete recording of a decision.
        
        Args:
            decision_id: ID of the decision
            state: Final state after decision
            status: success or error
            error: Error message if any
        """
        decision = self._get_decision(decision_id)
        if not decision:
            return
        
        end_time = datetime.now(timezone.utc)
        start_time = datetime.fromisoformat(decision.node_execution.start_time)
        duration_ms = (end_time - start_time).total_seconds() * 1000
        
        decision.node_execution.end_time = end_time.isoformat()
        decision.node_execution.duration_ms = duration_ms
        decision.node_execution.status = status
        decision.node_execution.error = error
        
        decision.state_after = self._sanitize_state(state)
        
        # Remove from active executions
        if decision_id in self.active_executions:
            del self.active_executions[decision_id]
        
        # Persist to disk
        self._persist_decision(decision)
    
    def replay_decision(self, decision_id: str) -> Optional[Dict[str, Any]]:
        """
        Replay a decision with full context.
        
        Returns:
            Complete decision record formatted for replay
        """
        decision = self._get_decision(decision_id)
        if not decision:
            return None
        
        return {
            "decision_id": decision.decision_id,
            "timestamp": decision.timestamp,
            "thread_id": decision.thread_id,
            
            "execution": {
                "node": decision.node_execution.node_name,
                "duration_ms": decision.node_execution.duration_ms,
                "status": decision.node_execution.status,
                "error": decision.node_execution.error
            },
            
            "prompt": {
                "model": decision.prompt_context.model,
                "temperature": decision.prompt_context.temperature,
                "template": decision.prompt_context.template,
                "final_prompt": decision.prompt_context.final_prompt,
                "variables": decision.prompt_context.variables
            },
            
            "output": {
                "text": decision.output_generated.raw_output,
                "parsed": decision.output_generated.parsed_output,
                "tool_calls": decision.output_generated.tool_calls,
                "resources": decision.output_generated.resources_found,
                "confidence": decision.output_generated.confidence,
                "tokens": decision.output_generated.token_count
            },
            
            "reasoning": {
                "type": decision.reasoning.decision_type,
                "rationale": decision.reasoning.rationale,
                "selected": decision.reasoning.selected_action,
                "alternatives": decision.reasoning.alternatives_considered,
                "confidence": decision.reasoning.confidence_score
            },
            
            "state_changes": {
                "before": decision.state_before,
                "after": decision.state_after
            }
        }
    
    def get_decision_chain(self, thread_id: str) -> List[Dict[str, Any]]:
        """
        Get the complete chain of decisions for a thread.
        
        Returns:
            List of decisions in chronological order
        """
        thread_decisions = [
            d for d in self.decisions 
            if d.thread_id == thread_id
        ]
        
        # Sort by timestamp
        thread_decisions.sort(key=lambda d: d.timestamp)
        
        return [
            {
                "decision_id": d.decision_id,
                "timestamp": d.timestamp,
                "node": d.node_execution.node_name,
                "status": d.node_execution.status,
                "duration_ms": d.node_execution.duration_ms,
                "decision_type": d.reasoning.decision_type,
                "action": d.reasoning.selected_action
            }
            for d in thread_decisions
        ]
    
    def visualize_decision_tree(self, thread_id: str) -> str:
        """
        Create a text visualization of the decision tree.
        
        Returns:
            ASCII art decision tree
        """
        chain = self.get_decision_chain(thread_id)
        
        if not chain:
            return "No decisions found for this thread"
        
        lines = [
            "=" * 80,
            f"DECISION TREE - Thread: {thread_id}",
            "=" * 80,
            ""
        ]
        
        for i, decision in enumerate(chain, 1):
            status_icon = "✅" if decision["status"] == "success" else "❌"
            lines.append(f"\n{i}. {status_icon} {decision['node']} ({decision['duration_ms']:.0f}ms)")
            lines.append(f"   Type: {decision['decision_type']}")
            lines.append(f"   Action: {decision['action']}")
            lines.append(f"   Time: {decision['timestamp']}")
            
            if i < len(chain):
                lines.append("   │")
                lines.append("   ↓")
        
        lines.append("\n" + "=" * 80)
        
        return "\n".join(lines)
    
    def analyze_performance(self, thread_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Analyze performance of decisions.
        
        Args:
            thread_id: Optional thread to analyze, or all threads
            
        Returns:
            Performance analysis
        """
        decisions = self.decisions
        if thread_id:
            decisions = [d for d in decisions if d.thread_id == thread_id]
        
        if not decisions:
            return {"message": "No decisions to analyze"}
        
        # Group by node
        by_node: Dict[str, List[float]] = {}
        for d in decisions:
            node = d.node_execution.node_name
            if node not in by_node:
                by_node[node] = []
            by_node[node].append(d.node_execution.duration_ms)
        
        # Calculate stats
        node_stats = {}
        for node, durations in by_node.items():
            node_stats[node] = {
                "count": len(durations),
                "avg_duration_ms": sum(durations) / len(durations),
                "min_duration_ms": min(durations),
                "max_duration_ms": max(durations)
            }
        
        # Overall stats
        all_durations = [d.node_execution.duration_ms for d in decisions]
        success_count = sum(1 for d in decisions if d.node_execution.status == "success")
        
        return {
            "total_decisions": len(decisions),
            "success_rate": success_count / len(decisions),
            "avg_duration_ms": sum(all_durations) / len(all_durations),
            "total_duration_ms": sum(all_durations),
            "node_stats": node_stats,
            "unique_threads": len(set(d.thread_id for d in decisions))
        }
    
    def _get_decision(self, decision_id: str) -> Optional[DecisionRecord]:
        """Get decision by ID"""
        for decision in self.decisions:
            if decision.decision_id == decision_id:
                return decision
        return None
    
    def _sanitize_state(self, state: Dict[str, Any]) -> Dict[str, Any]:
        """Sanitize state for storage"""
        sanitized = {}
        
        for key, value in state.items():
            if isinstance(value, (str, bytes)) and len(value) > 5000:
                sanitized[key] = f"<truncated: {len(value)} chars>"
            elif isinstance(value, list) and len(value) > 30:
                sanitized[key] = f"<truncated: {len(value)} items>"
            else:
                try:
                    json.dumps(value)
                    sanitized[key] = value
                except (TypeError, ValueError):
                    sanitized[key] = str(value)[:500]
        
        return sanitized
    
    def _persist_decision(self, decision: DecisionRecord):
        """Persist decision to disk"""
        timestamp_str = decision.timestamp.replace(":", "-").split(".")[0]
        filename = f"decision_{decision.decision_id}_{timestamp_str}.json"
        filepath = self.storage_path / filename
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(decision.to_json())
    
    def export_replay_script(self, thread_id: str, output_path: Optional[Path] = None) -> str:
        """
        Export a replay script for debugging/testing.
        
        Returns:
            Path to the generated script
        """
        chain = self.get_decision_chain(thread_id)
        
        if not chain:
            return "No decisions to export"
        
        script_lines = [
            "# Auto-generated Decision Replay Script",
            f"# Thread: {thread_id}",
            f"# Generated: {datetime.now(timezone.utc).isoformat()}",
            "",
            "from src.monitoring.decision_replay import DecisionReplayManager",
            "",
            "manager = DecisionReplayManager()",
            ""
        ]
        
        for decision in chain:
            script_lines.append(f"# Decision: {decision['decision_id']}")
            script_lines.append(f"replay = manager.replay_decision('{decision['decision_id']}')")
            script_lines.append("print(replay)")
            script_lines.append("")
        
        script_content = "\n".join(script_lines)
        
        if output_path is None:
            output_path = self.storage_path / f"replay_{thread_id}.py"
        
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(script_content)
        
        return str(output_path)
